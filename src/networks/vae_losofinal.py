# -*- coding: utf-8 -*-
"""vae_losofinal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16GYbb0H-P5QFc8eGJ8Yp7fX8Vcbyk00_
"""

#@title File imports
"""  
from google.colab import drive
drive.mount('/content/drive')

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
"""
#@title Imports

#!pip install wandb -qU

import tensorflow as tf
import numpy as np
import keras
from keras.utils import np_utils
import matplotlib.pyplot as plt
import tensorflow_probability
tfd = tensorflow_probability.distributions

import pickle
import itertools
import statistics as st
import csv
import time
import math
import shutil

import wandb
from wandb.keras import WandbCallback
import os
from my_libraries.data_instance import Dataset
import absl.logging
absl.logging.set_verbosity(absl.logging.ERROR)
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  print(
      '\n\nThis error most likely means that this notebook is not '
      'configured to use a GPU.  Change this in Notebook Settings via the '
      'command palette (cmd/ctrl-shift-P) or the Edit menu.\n\n')
  raise SystemError('GPU device not found')


#@title Wandb settings

os.environ["WANDB_CONSOLE"] = "off"

os.environ['WANDB_NOTEBOOK_NAME'] = 'vae_loso'
wandb.login()

sweep_config={'method':'grid'}

parameter_dict ={'fold_number':{'values': [1,2,3,4,5,6,7,8,9,10,11]}}

sweep_config['parameters'] = parameter_dict 

sweep_id = wandb.sweep(sweep_config, project="team activity recognition")

#@title General settings
np.random.seed(1671) 

INPUT_REPRESENTATION_SIZE = 130
NUMBER_OF_FRAMES= 130
BATCH_SIZE = 5
TEST_SIZE = 50
FEATURE_SIZE = 20

#CROSSVAL_ITERATIONS = 3
NUM_FINAL_NETWORK_EPOCHS = 200
NUMBER_OF_CLASSES = 9
POINTS_PER_CLASS = 100
#OPTIMIZER=tf.keras.optimizers.SGD(0.1)
#dataset_name =  "LOSO_dataset.pickle"
dataset_name =  "LOSO2.pickle" #change for baseline case
GROUP_NAME = "Rehearsal"
natural_test_set_name = "LOSO2.pickle"
print("Insert log name for the training")
log_name = input()

#@title VAE settings

STGCN_LAYER_SIZE = 64
TGCN_KERNEL_SIZE = 9
NUM_LATENTS = 3900
NUM_CHANNELS = 3
P_DROPOUT= 0.3
NUM_VAE_EPOCHS = 5

def multi_normal(loc, log_scale):
  return tfd.Independent(
      distribution=tfd.Normal(loc=loc, scale=tf.exp(log_scale)),
      reinterpreted_batch_ndims=0)

prior = multi_normal(tf.zeros(shape=(BATCH_SIZE, int(NUM_LATENTS/2)), dtype=tf.float64), tf.zeros(shape=(BATCH_SIZE, int(NUM_LATENTS/2)), dtype=tf.float64))


strategy = tf.distribute.MirroredStrategy(devices=None)
print("Number of GPUs detected: ", strategy.num_replicas_in_sync)
GLOBAL_BATCH_SIZE = strategy.num_replicas_in_sync * BATCH_SIZE
AUTOTUNE = tf.data.AUTOTUNE
TRAIN_STEPS = math.ceil(POINTS_PER_CLASS*9/GLOBAL_BATCH_SIZE)

#@title Tools for STGCN

def edge2mat(link, num_node):
    A = np.zeros((num_node, num_node))
    for i, j in link:
        #print(i,j)
        A[j, i] = 1
    return A

def normalize_digraph(A):  # 除以每列的和
    Dl = np.sum(A, 0)
    h, w = A.shape
    Dn = np.zeros((w, w))
    for i in range(w):
        if Dl[i] > 0:
            Dn[i, i] = Dl[i] ** (-1)
    AD = np.dot(A, Dn)
    return AD

def get_spatial_graph(num_node, self_link, inward, outward):
    I = edge2mat(self_link, num_node)
    In_bet = edge2mat(inward, num_node)
    In = normalize_digraph(In_bet)
    Out_bet = edge2mat(outward, num_node)
    Out = normalize_digraph(Out_bet)
    A = np.stack((I, In, Out))
    return A

num_node = 20

self_link = [(i, i) for i in range(num_node)]

inward_ori_index = [[0,1],[1,2],[2,3],[3,4],[4,5],[2,6],[6,7],[7,8],[2,9],
                    [10,11],[11,12],[12,13],[13,14],[14,15],[12,16],
                    [16,17],[17,18],[12,19]]

#inward_ori_index = [(0,1),(1,2),(2,3),(3,4),(1,5),(5,6),(6,7),(1,8),
#(8,9),(9,10),(10,11),(8,12),(12,13),(13,14)]
inward = [(i - 1, j - 1) for (i, j) in inward_ori_index]
outward = [(j, i) for (i, j) in inward]
neighbor = inward + outward

class Graph:
    def __init__(self, labeling_mode='spatial'):
        self.A = self.get_adjacency_matrix(labeling_mode)
        self.num_node = num_node
        self.self_link = self_link
        self.inward = inward
        self.outward = outward
        self.neighbor = neighbor
    def get_adjacency_matrix(self, labeling_mode=None):
        if labeling_mode is None:
            return self.A
        if labeling_mode == 'spatial':
            A = get_spatial_graph(num_node, self_link, inward, outward)
        else:
            raise ValueError()
        return A

REGULARIZER = tf.keras.regularizers.l2(l=0.0001)
INITIALIZER = tf.keras.initializers.VarianceScaling(scale=2.,
                                                    mode="fan_out",
                                                    distribution="truncated_normal",seed=0)

    #os.environ['DISPLAY'] = 'localhost:11.0'
A = Graph('spatial').get_adjacency_matrix()
print(A.shape)
for i in A:
  plt.imshow(i, cmap='gray')
  plt.show()
print(A)

"""From https://github.com/kdkalvik/ST-GCN/blob/master/model/stgcn.py
The basic module for applying a spatial graph convolution.<br>
    Args:<br>
        filters (int): Number of channels produced by the convolution<br>
        kernel_size (int): Size of the graph convolving kernel<br>
    Shape:<br>
        - Input[0]: Input graph sequence in :math:`(N, C, T, V)` format<br>
        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format<br>
        - Output[0]: Output graph sequence in :math:`(N, out_channels, T, V)` format<br>
        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)` format<br>
        where<br>
            :math:`N` is a batch size<br>
            :math:`K` is the spatial kernel size<br>
            :math:`T` is a length of the sequence<br>
            :math:`V` is the number of graph nodes<br>
            :math:`C` is the number of incoming channels<br>

"""

#@title SGCN

class SGCN(tf.keras.Model):
    def __init__(self, filters, kernel_size=3):
        super().__init__()
        self.kernel_size = kernel_size
        
        self.conv = tf.keras.layers.Conv2D(filters*kernel_size,
                                           kernel_size=1,
                                           padding='same',
                                           kernel_initializer=INITIALIZER,
                                           data_format='channels_first',
                                           kernel_regularizer=REGULARIZER)
        graph = Graph()
        self.A = tf.Variable(graph.A,
                        dtype=tf.float32,
                        trainable=False,
                        name='adjacency_matrix')

    # N, C, T, V
    def call(self, x, training):
        x = self.conv(x)
        N = tf.shape(x)[0]
        C = x.shape[1]
        T = x.shape[2]
        V = x.shape[3]
        
        x = tf.reshape(x, [N, self.kernel_size, C//self.kernel_size, T, V])
        x = tf.einsum('nkctv,kvw->nctw', x, self.A)
        return x

"""title Spatio-temporal graph convolution

rom https://github.com/kdkalvik/ST-GCN/blob/master/model/stgcn.py

Applies a spatial temporal graph convolution over an input graph sequence.<br>
    Args:<br>
        filters (int): Number of channels produced by the convolution<br>
        kernel_size (tuple): Size of the temporal convolving kernel and graph convolving kernel<br>
        stride (int, optional): Stride of the temporal convolution. Default: 1<br>
        activation (activation function/name, optional): activation function to use<br>
        residual (bool, optional): If ``True``, applies a residual mechanism. Default: ``True``<br>
        downsample (bool, optional): If ``True``, applies a downsampling residual mechanism. Default: ``True``<br>
                                     the value is used only when residual is ``True``<br>
    Shape:<br>
        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)` format<br>
        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format<br>
        - Output[0]: Outpu graph sequence in :math:`(N, out_channels, T_{out}, V)` format<br>
        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)` format<br>
        where<br>
            :math:`N` is a batch size,<br>
            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,<br>
            :math:`T_{in}/T_{out}` is a length of input/output sequence,<br>
            :math:`V` is the number of graph nodes.<br>
"""

#@title STGCN

class STGCN(tf.keras.Model):
    def __init__(self, filters, kernel_size=[9, 3], stride=1, activation='relu',
                 residual=False, downsample=False):
        super().__init__()
        self.sgcn = SGCN(filters, kernel_size=kernel_size[1])
        self.tgcn = tf.keras.Sequential()
        #self.tgcn.add(tf.keras.layers.BatchNormalization(axis=1))
        self.tgcn.add(tf.keras.layers.Activation(activation))
        self.tgcn.add(tf.keras.layers.Conv2D(filters,
                                                kernel_size=[kernel_size[0], 1],
                                                strides=[stride, 1],
                                                padding='same',
                                                kernel_initializer=INITIALIZER,
                                                data_format='channels_first',
                                                kernel_regularizer=REGULARIZER),)
        self.tgcn.add(tf.keras.layers.BatchNormalization(axis=1))
        self.act = tf.keras.layers.Activation(activation)
        if not residual:
            self.residual = lambda x, training=False: 0
        elif residual and stride == 1 and not downsample:
            self.residual = lambda x, training=False: x
        else:
            self.residual = tf.keras.Sequential()
            self.residual.add(tf.keras.layers.Conv2D(filters,
                                                        kernel_size=[1, 1],
                                                        strides=[stride, 1],
                                                        padding='same',
                                                        kernel_initializer=INITIALIZER,
                                                        data_format='channels_first',
                                                        kernel_regularizer=REGULARIZER))
            self.residual.add(tf.keras.layers.BatchNormalization(axis=1))
        graph = Graph()
        self.A = tf.Variable(graph.A,
                            dtype=tf.float32,
                            trainable=False,
                            name='adjacency_matrix')
    def call(self, x, training):
        res = self.residual(x, training=training)
        x = self.sgcn(x, training=training)
        x = self.tgcn(x, training=training)
        x += res
        x = self.act(x)
        return x

#@title VAE definition
class VAE(keras.Model):
  def __init__(self, lat_dim):
    super(VAE,self).__init__()
    
    self.lat_dim = lat_dim
    
    self.encoder = keras.Sequential([
      keras.layers.InputLayer(input_shape=(NUM_CHANNELS, NUMBER_OF_FRAMES, FEATURE_SIZE), dtype="float32"), 
      keras.layers.Conv2D(FEATURE_SIZE,NUM_CHANNELS, input_shape = (NUM_CHANNELS, NUMBER_OF_FRAMES, FEATURE_SIZE)), #Uncomment for lstm case
      keras.layers.Reshape((NUMBER_OF_FRAMES-2,FEATURE_SIZE)), #Uncomment for lstm case
     
      keras.layers.SimpleRNN(250), #Uncomment for lstm case
      #STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]), #Uncomment for stgcn case
      #STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]), #Uncomment for stgcn case
      #STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]), #Uncomment for stgcn case
      #STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]), #Uncomment for stgcn case
      #keras.layers.AveragePooling2D(pool_size=(2, 2)), #Uncomment for stgcn case
      keras.layers.Flatten(),
      keras.layers.Dense(int(self.lat_dim*(2/3)),activation='relu'),
      keras.layers.Dropout(P_DROPOUT),
      keras.layers.Dense(self.lat_dim,activation='relu'),
      keras.layers.Dropout(P_DROPOUT)
    ])
    self.decoder = keras.Sequential([
      keras.layers.InputLayer(input_shape=(int(self.lat_dim/2),), dtype="float32"),
      keras.layers.Dense(self.lat_dim),
      keras.layers.Dense(2*self.lat_dim),
      keras.layers.Dense(4*self.lat_dim, activation='tanh'),
      keras.layers.Reshape(target_shape=(2*NUM_CHANNELS,NUMBER_OF_FRAMES,FEATURE_SIZE))
    ])
  def get_encoder(self):
    return self.list_of_layers
    
  def encode(self, data_batch):
    mean, var = tf.split(self.encoder(data_batch),num_or_size_splits=2,axis=1)
    mean = tf.cast(mean,dtype=tf.float64)
    var = tf.cast(var,dtype=tf.float64)
    return multi_normal(loc=tf.squeeze(mean), log_scale=tf.squeeze(var))

  def decode(self, data_representation):
    decoded = self.decoder(data_representation)
    #print("Shape of decoded data: ", decoded.shape)
    mean, var = tf.split(decoded,num_or_size_splits=2,axis=1)
    mean = tf.cast(mean,dtype=tf.float64)
    #print("Shape of probability distribution: ", mean.shape)
    var = tf.cast(var,dtype=tf.float64)
    return multi_normal(loc=tf.squeeze(mean), log_scale=tf.squeeze(var))

#@title VAE loss

def vae_loss(data_prob, var_post, prior):
  likelihood_term= tf.compat.v1.log(data_prob)
    # Reduce mean over the batch dimensions
  likelihood_term = tf.reduce_sum(likelihood_term,axis=[1,2,3])/GLOBAL_BATCH_SIZE
  kl_term=tfd.kl_divergence(var_post, prior)  
    # Reduce over the batch dimension.
  kl_term = tf.reduce_sum(kl_term)/GLOBAL_BATCH_SIZE
  return kl_term - likelihood_term

#@title Training step for distributed environments

def train_step(real_data,vae,prior,optimizer):
  #print("Entered here1")
  #describe_distributions(prior)
  loss = []
  with tf.GradientTape()as tape:
    var_post = vae.encode(tf.squeeze(tf.cast(real_data,dtype=np.float32)))
    sample_from_var_post=var_post.sample()
    decoded= vae.decode(sample_from_var_post)
    data_batch = tf.cast(real_data,dtype=np.float64)
    data_prob = decoded.prob(data_batch)
    #print("Entered here2")
    #describe_distributions(prior)
    loss = vae_loss(data_prob, var_post, prior)
    #print("Entered here3")
    #describe_distributions(prior)

  gradients = tape.gradient(loss, vae.trainable_variables)
  optimizer.apply_gradients(
    (grad, var) 
    for (grad, var) in zip(gradients, vae.trainable_variables)
    if grad is not None
  )
  #print("Entered here f")
  #describe_distributions(prior)
  return loss

def distributed_train_step(x,vae,optimizer):
  #print("Entered here")
  #describe_distributions(pr)
  #a = pr.copy()
  results = strategy.run(train_step, args=(x,vae,prior,optimizer))
  #describe_distributions(poisson_distributions)
  #print("Left strategy")
  results = reduce_list(results)
  #describe_distributions(pr)
  #print("List reduced")
  #pr =a.copy()
  return results

def reduce_list(l):
  return strategy.reduce(tf.distribute.ReduceOp.SUM, l, axis=None)

def train (training_set,vae,optimizer):
  results = []
  d_t = tf.function(distributed_train_step)
  for x in training_set:
    result = d_t([x],vae,optimizer)
    #print("Left distributed")
    results.append(result)
  
  final_loss = tf.reduce_mean(tf.convert_to_tensor(results))
  
  return final_loss

#@title Variables for storing results

trained_predictions = []
untrained_predictions = []
labels = []

trained_natural_predictions = []
untrained_natural_predictions = []
natural_labels = []

start0 = time.perf_counter()
time_trained = []
time_untrained = []
time_vae= []

#@title Variables for preparing data

dataset=Dataset([],[],[],[],[],[])
dataset.load(dataset_name)
dataset.min_max(-2.5,1.75,0,1)

tags = ['01','02','03','04','05','06','07','08','09','10','11']

#loso = pickle.load(open("LOSO_dataset.pickle", 'rb'))
#loso = folds[0]

natural_dataset = Dataset([],[],[],[],[],[])
natural_dataset.load(natural_test_set_name)
natural_dataset.min_max(-2.5,1.75,0,1)
natural_test_set = natural_dataset.get_data_as_array().transpose([0,3,1,2]).astype(np.float32)

def multi_normal(loc, log_scale):
  return tfd.Independent(
      distribution=tfd.Normal(loc=loc, scale=tf.exp(log_scale)),
      reinterpreted_batch_ndims=0)

#@title Wandb run

def wandb_train(config=None):

  with wandb.init(config=config) as run:
        #print("Here")
        project = "team_activity_recognition"

        config = wandb.config

        fold_number = config.fold_number

        #tag = tags[int(fold_number-1)]
        tag = str(fold_number) #for the baseline case

        run.name = "s"+tag

        tf.keras.backend.clear_session()

        VERBOSE = 0

        with strategy.scope():

          vae=VAE(NUM_LATENTS)
          optimizer = tf.keras.optimizers.Adam(0.001, beta_1=0.9, beta_2=0.9)

        current_dataset = dataset.copy_dataset()
        print("Subject ",run.name, "as test set")
        #natural_labels.append(natural_te_lab)
  
        #Separation from training and test set

        #current_dataset.isolate_subject(run.name,[[0,3],[0,3]])
        current_dataset.isolate_subject(run.name,[[0,2],[3,5]]) #for the baseline case
        training_set_initial = current_dataset.get_data_as_array().transpose([0,3,1,2]).astype(np.float32)
        BATCH_NUMBER = int(np.floor(training_set_initial.shape[0]/GLOBAL_BATCH_SIZE))
        training_set_initial = training_set_initial[0:GLOBAL_BATCH_SIZE*BATCH_NUMBER,:,:,:]
        print("Generated training set")
        test_set_initial = current_dataset.get_test_as_array().transpose([0,3,1,2]).astype(np.float32)
        print("Generated test set")
  
        #Conversion of datasets to Tensorflow format
        training_set = tf.data.Dataset.from_tensor_slices(training_set_initial)
        test_set = tf.data.Dataset.from_tensor_slices(test_set_initial)

        #Memory optimisation for distributed strategy
        #training_set = training_set.cache()
        #test_set = test_set.cache()
        #training_set.shuffle(9100)
        training_set.prefetch(buffer_size = AUTOTUNE)
        training_set = training_set.batch(GLOBAL_BATCH_SIZE)
        options = tf.data.Options()
        options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF
        training_set = training_set.with_options(options)

        #Including datasets in the distributed strategy
        training_set=strategy.experimental_distribute_dataset(training_set)

        #Generation of training and test labels
        tr_lab = current_dataset.get_labels()[0:GLOBAL_BATCH_SIZE*BATCH_NUMBER] 
        output_training = np_utils.to_categorical(tr_lab, NUMBER_OF_CLASSES)
  
        te_lab = current_dataset.get_test_labels()
        labels.append(te_lab)  
        output_test = np_utils.to_categorical(te_lab,NUMBER_OF_CLASSES)

        natural_te_lab = natural_dataset.get_labels()
        natural_labels.append(natural_te_lab)
        natural_te_lab = np_utils.to_categorical(natural_te_lab, NUMBER_OF_CLASSES)

        #Run training of VAE 
        #print("Here")

        #prior_mean = tf.zeros(shape=(BATCH_SIZE, int(NUM_LATENTS/2)), dtype=tf.float64)
        #prior_scale = tf.zeros(shape=(BATCH_SIZE, int(NUM_LATENTS/2)), dtype=tf.float64)
        #prior = multi_normal(prior_mean,prior_scale)
  


        print("Training VAE")

        results = []
  
        #vae = VAE(lat_dim=200)
        start2 = time.perf_counter()
        for epoch in range(NUM_VAE_EPOCHS):
          result = train(training_set,vae,optimizer)
          print('Epoch: {}, Loss: {}'.format(epoch+1, result))
          results.append(result)
          wandb.log({'VAE loss':result,'VAE epoch':epoch+1})
        el2 = time.perf_counter() - start2
        #all_losses.append(results)

        vae.encoder.save('weights_' + log_name + '_' + tag)
        print('Training time of VAE: ',el2)
        time_vae.append(el2)
  
        '''prova = keras.Sequential([
              keras.layers.InputLayer(input_shape=(NUM_CHANNELS, NUMBER_OF_FRAMES, FEATURE_SIZE), dtype="float32"),
              STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]),
              STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]),
              STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]),
              STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3])
           ])
        prova.load_weights('weights_'+tag,by_name=True)
        input()'''
        
        #Get the encoder and use it for classification
        tr_en = keras.models.load_model('weights_' + log_name + '_' +tag)
        #trained_encoder = keras.Sequential(tr_en.layers[0:6]) #Uncomment for the stgcn case
        trained_encoder = keras.Sequential(tr_en.layers[0:5]) #Uncomment for the lstm case
        trained_encoder.add(keras.layers.Dense(NUMBER_OF_CLASSES, activation='softmax'))

        for layer in trained_encoder.layers[:-1]:
          layer.trainable = False 

        trained_encoder.compile(loss="categorical_crossentropy", optimizer=tf.keras.optimizers.SGD(0.1), 
                               metrics=["accuracy"])
        print("Training network, after having loaded the model")
        start3 = time.perf_counter()
        trained_history = trained_encoder.fit(training_set_initial, output_training, 
                                        batch_size=BATCH_SIZE, epochs=NUM_FINAL_NETWORK_EPOCHS, 
                                        verbose=VERBOSE, validation_data=(test_set_initial, output_test))
                                        #callbacks=[WandbCallback()])
        trained_encoder.summary()
        el3 = time.perf_counter() - start3


        for j in range(NUM_FINAL_NETWORK_EPOCHS): 
          wandb.log({'VAE-based loss':trained_history.history['loss'][j], 
                     'VAE-based accuracy':trained_history.history['accuracy'][j], 
                     'VAE-based validation loss':trained_history.history['val_loss'][j],
                     'VAE-based validation accuracy':trained_history.history['val_accuracy'][j],
                     'VAE-based epoch':j+1})

        print('Training time of transferred network: ',el3)
        time_trained.append(el3)

        print("Testing VAE-based network with artificial instances")
        preds = trained_encoder.predict(test_set_initial, verbose=VERBOSE)
        for j in range(len(preds)):
          pred = np.where(preds[j]==np.max(preds[j]))[0][0]
          trained_predictions.append(pred)

        print("Testing VAE-based network with natural instances")
        natural_preds = trained_encoder.predict(natural_test_set, verbose=VERBOSE)
        for j in range(len(natural_preds)):
          natural_pred = np.where(natural_preds[j]==np.max(natural_preds[j]))[0][0]
          trained_natural_predictions.append(natural_pred)

        del el2
        del el3
        del tr_en
        del trained_encoder
        del trained_history
        shutil.rmtree('weights_' + log_name + '_' + tag) #Comment out if you want to keep the model

        #Initialise the same untrained network, train it through backpropagation and test it for classification
        print("Training network from scratch")

        untrained_encoder = keras.Sequential([
            keras.layers.InputLayer(input_shape=(NUM_CHANNELS, NUMBER_OF_FRAMES, FEATURE_SIZE), dtype="float32"), #Uncomment for lstm case 
            keras.layers.Conv2D(FEATURE_SIZE,NUM_CHANNELS, input_shape = (NUM_CHANNELS, NUMBER_OF_FRAMES, FEATURE_SIZE)), #Uncomment for lstm case 
            keras.layers.Reshape((NUMBER_OF_FRAMES-2,FEATURE_SIZE)), #Uncomment for lstm case
            keras.layers.SimpleRNN(250), #Uncomment for lstm case 
            #STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]), #Uncomment for stgcn case 
            #STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]), #Uncomment for stgcn case 
            #STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]), #Uncomment for stgcn case 
            #STGCN(filters=STGCN_LAYER_SIZE, kernel_size=[TGCN_KERNEL_SIZE,3]), #Uncomment for stgcn case 
            #keras.layers.AveragePooling2D(pool_size=(2, 2)), #Uncomment for stgcn case 
            keras.layers.Flatten(),
            #keras.layers.Dense(2533,activation='relu'),
            #keras.layers.Dropout(P_DROPOUT),
            #keras.layers.Dense(NUM_LATENTS,activation='relu'),
            #keras.layers.Dropout(P_DROPOUT),
            keras.layers.Dense(NUMBER_OF_CLASSES, activation='softmax')
        ])
        #print("Here")

        untrained_encoder.compile(loss="categorical_crossentropy", optimizer=tf.keras.optimizers.SGD(0.1), metrics=["accuracy"])
  
        start1 = time.perf_counter()
        untrained_history = untrained_encoder.fit(training_set_initial, output_training, batch_size=BATCH_SIZE,
                                                  epochs=NUM_FINAL_NETWORK_EPOCHS,verbose=VERBOSE,
                                                  validation_data = (test_set_initial, output_test))
                                      #callbacks=[WandbCallback()])
        el1 = time.perf_counter() - start1
        time_untrained.append(el1)
        print('Training time of classical method: ',el1)

        for j in range(NUM_FINAL_NETWORK_EPOCHS):
          wandb.log({'Standard loss':untrained_history.history['loss'][j],
                     'Standard accuracy':untrained_history.history['accuracy'][j],
                     'Standard validation loss':untrained_history.history['val_loss'][j],
                     'Standard validation accuracy':untrained_history.history['val_accuracy'][j],
                     'Standard  epoch':j+1})

        preds = untrained_encoder.predict(test_set_initial, verbose=VERBOSE)

        print("Testing standard network with artificial instances")
        for j in range(len(preds)):
          pred = np.where(preds[j]==np.max(preds[j]))[0][0]
          untrained_predictions.append(pred)

        natural_preds = untrained_encoder.predict(natural_test_set, verbose=VERBOSE)

        print("Testing standard network with natural instances")
        for j in range(len(natural_preds)):
          natural_pred = np.where(natural_preds[j]==np.max(natural_preds[j]))[0][0]
          untrained_natural_predictions.append(natural_pred)
        #print("Here")
        #all_untrained_train_acc.append(untrained_history.history['accuracy'])
        #all_untrained_train_loss.append(untrained_history.history['loss'])
        #all_untrained_train_acc_val.append(untrained_history.history['val_accuracy'])
        #all_untrained_train_loss_val.append(untrained_history.history['val_loss'])

        el_tot = time.perf_counter() - start0
        print('Total time: ',el_tot)

        #Delete fold crossvalidation variables, because TensorFlow does not
        del el1
        #del el2
        #del el3
        del training_set
        del training_set_initial
        del test_set_initial
        del test_set
        del tr_lab
        del te_lab
        del natural_te_lab
        #del tr_en
        #del trained_encoder
        #del trained_history
        #shutil.rmtree('weights_' + log_name + '_' + tag) #Comment out if you want to keep the model
        del untrained_encoder
        del untrained_history
        del pred
        del preds
        del natural_pred
        del natural_preds


#@title Start the training!

wandb.agent(sweep_id, wandb_train, count = 3) #Change to 3 for baseline case 

#@title Store the results

labels_merged = labels[0]
for i in range(len(labels)-1):
  labels_merged = labels_merged + labels[i+1]

natural_labels_merged = natural_labels[0]
for i in range(len(natural_labels)-1):
  natural_labels_merged = natural_labels_merged + natural_labels[i+1]


#labels_tf = tf.Variable(labels_merged)
#untrained_tf = tf.Variable(untrained_predictions)
#trained_tf = tf.Variable(trained_predictions)

#trained_confusion = tf.math.confusion_matrix(labels_tf,trained_tf)
#untrained_confusion = tf.math.confusion_matrix(labels_tf,untrained_tf)

with open('confusion_logs/' + log_name + '_For_confusions.csv', 'w', encoding='UTF8') as f:
  writer = csv.writer(f)

  # write the header
  writer.writerow([labels_merged,untrained_predictions,trained_predictions,
                  natural_labels_merged,untrained_natural_predictions,trained_natural_predictions])
  #writer.writerow([labels_merged,trained_predictions,natural_labels_merged,trained_natural_predictions])
  #writer.writerow([labels_merged,untrained_predictions,natural_labels_merged,untrained_natural_predictions])

with open('confusion_logs/' + log_name + '_Time_performances.csv', 'w', encoding='UTF8') as f:
  writer = csv.writer(f)

  writer.writerow([time_vae,time_trained,time_untrained])
  #writer.writerow([time_vae,time_trained])
  #writer.writerow([time_vae,time_untrained])

